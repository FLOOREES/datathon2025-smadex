{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac31fca1",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58875f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbf760f",
   "metadata": {},
   "source": [
    "# Set the root path to ease the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d4400f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: c:\\Users\\adria.flores\\Documents\\Projects\\hacks\\datathon2025-smadex\n",
      "Contenido de ./data: ['sample_submission.csv', 'test', 'train']\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ROOT = os.getcwd()\n",
    "\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"Contenido de ./data:\", os.listdir(os.path.join(PROJECT_ROOT, \"data\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df955ff6",
   "metadata": {},
   "source": [
    "# Read the train parquet and split it in train and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce7d7fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas object que pasamos a string (train): ['advertiser_bundle', 'advertiser_category', 'advertiser_subcategory', 'advertiser_bottom_taxonomy_level', 'carrier', 'country', 'region', 'dev_make', 'dev_model', 'dev_os', 'dev_osv', 'hour', 'release_date', 'avg_daily_sessions', 'avg_duration', 'bcat', 'bcat_bottom_taxonomy', 'bundles_cat', 'bundles_cat_bottom_taxonomy', 'bundles_ins', 'city_hist', 'country_hist', 'cpm', 'cpm_pct_rk', 'ctr', 'ctr_pct_rk', 'dev_language_hist', 'dev_osv_hist', 'first_request_ts_bundle', 'first_request_ts_category_bottom_taxonomy', 'hour_ratio', 'iap_revenue_usd_bundle', 'iap_revenue_usd_category', 'iap_revenue_usd_category_bottom_taxonomy', 'last_buy_ts_bundle', 'last_buy_ts_category', 'last_install_ts_bundle', 'last_install_ts_category', 'advertiser_actions_action_count', 'advertiser_actions_action_last_timestamp', 'user_actions_bundles_action_count', 'user_actions_bundles_action_last_timestamp', 'last_advertiser_action', 'new_bundles', 'num_buys_bundle', 'num_buys_category', 'num_buys_category_bottom_taxonomy', 'region_hist', 'rev_by_adv', 'rwd_prank', 'user_bundles', 'user_bundles_l28d', 'whale_users_bundle_num_buys_prank', 'whale_users_bundle_revenue_prank', 'whale_users_bundle_total_num_buys', 'whale_users_bundle_total_revenue', 'row_id']\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import dask\n",
    "dask.config.set({\"dataframe.convert-string\": False})\n",
    "\n",
    "DATASET_PATH = \"data/train/train\"\n",
    "\n",
    "train_ddf = dd.read_parquet(\n",
    "    DATASET_PATH,\n",
    "    filters=[(\"datetime\", \"<\", \"2025-10-07-00-00\")],\n",
    ")\n",
    "\n",
    "val_ddf = dd.read_parquet(\n",
    "    DATASET_PATH,\n",
    "    filters=[\n",
    "        (\"datetime\", \">=\", \"2025-10-07-00-00\"),\n",
    "        (\"datetime\", \"<\",  \"2025-10-08-00-00\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "obj_cols_train = list(train_ddf.select_dtypes(include=[\"object\"]).columns)\n",
    "obj_cols_val   = list(val_ddf.select_dtypes(include=[\"object\"]).columns)\n",
    "\n",
    "print(\"Columnas object que pasamos a string (train):\", obj_cols_train)\n",
    "\n",
    "train_ddf = train_ddf.astype({c: \"string\" for c in obj_cols_train})\n",
    "val_ddf   = val_ddf.astype({c: \"string\" for c in obj_cols_val})\n",
    "\n",
    "# Ahora sÃ­: guardar splits\n",
    "train_ddf.to_parquet(\"data/split/train\", write_index=False)\n",
    "val_ddf.to_parquet(\"data/split/val\", write_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80ce300",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = dd.read_parquet(DATASET_PATH, columns=[\"datetime\", \"buyer_d7\"])\n",
    "\n",
    "train_ddf = ddf[ddf[\"datetime\"] < \"2025-10-07-00-00\"]\n",
    "val_ddf   = ddf[(ddf[\"datetime\"] >= \"2025-10-07-00-00\") & (ddf[\"datetime\"] < \"2025-10-08-00-00\")]\n",
    "\n",
    "def buyer_stats(ddf, name):\n",
    "    total = ddf.shape[0].compute()\n",
    "    buyers = ddf[\"buyer_d7\"].sum().compute()\n",
    "    rate   = ddf[\"buyer_d7\"].mean().compute()\n",
    "    print(f\"{name}: total={total}, buyers={buyers}, rate={rate:.6f}\")\n",
    "\n",
    "buyer_stats(train_ddf, \"TRAIN\")\n",
    "buyer_stats(val_ddf,   \"VAL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197968bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nos quedamos solo con la fecha (sin hora)\n",
    "train_ddf_dates = train_ddf.assign(\n",
    "    date=train_ddf[\"datetime\"].str.slice(0, 10)  # si es string tipo \"2025-10-01-00-00\"\n",
    ")\n",
    "\n",
    "buyers_by_date = (\n",
    "    train_ddf_dates[[\"date\", \"buyer_d7\"]]\n",
    "    .groupby(\"date\")\n",
    "    .mean()\n",
    "    .compute()\n",
    "    .rename(columns={\"buyer_d7\": \"buyer_d7_rate\"})\n",
    ")\n",
    "\n",
    "print(buyers_by_date)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datathon2025-smadex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
